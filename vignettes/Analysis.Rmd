---
title: "Network regularization on TCGA Cancer Data"
author: "André Veríssimo"
date: "`r Sys.Date()`"
output:
  github_document:
    fig_width: 10
  html_document:
    toc: true
    self_contained: true
    number_sections: true
    fig_width: 10
  BiocStyle::html_document:
    number_sections: yes
    toc: true
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Example for Classification Data -- Breast Invasive Carcinoma}
  %\VignetteEncoding{UTF-8}
params:
  project: 'brca' # skcm prad brca
  tissue: 'primary.solid.tumor' # primary.solid.tumor metastatic solid.tissue.normal
  coding.genes: !r TRUE
  degree.unweighted: !r TRUE
  degree.correlation: 'pearson'
  degree.cutoff: !r 0
  #
  # Normalization of xdata
  log2: !r TRUE
  normalization: 'max' # center, max, none
  #
  degree.type: "string" # covariance, correlation, correlation.inv, oldie, sparsebn, string
  #
  handle.duplicates: 'keep_first' # keep_all , keep_first
  #
  # glmnet parameter
  alpha: !r .2
  # subset of variables to be used (Inf for all)
  subset: !r Inf
  train: !r .8
  # number of times that training set is tested
  ntimes: !r 1000
  # target variables that models should output
  target.vars: !r list(glmnet = 83, hub = 39, orphan = 101)
  #
  seed: !r 1985
  n.cores: !r 14
  #
  calc.params.old: !r FALSE
---

# Overview

**Data**

* *TCGA project*: **`r params$project`**
* *Tissue type*: **`r params$tissue`**
    * `r if(params$coding.genes) {'Only using coding genes'} else {'Using all genes (coding and non-coding)'}`
* *Degree calculation*: **`r params$degree.type`**

**Normalization**

* *LOG2 transform*: **`r if (params$log2) { 'yes' } else { 'no' }`**
* *Gene by gene*: **`r params$normalization`**

**Model options**

* *Alpha in ElasticNet*: **`r params$alpha`**
* *Train/Test*: **`r params$train * 100`%**
* *Target variables*: `r paste(sapply(names(params$target.vars), function(ix) {sprintf('%s: %d', ix, params$target.vars[[ix]])}), collapse = ', ')`
  
**Network processing**

* *Degree calculation*: `r params$degree.type`
* *Edge cutoff*: **`r params$degree.cutoff`**
* **`r if (params$degree.unweighted) { 'Unweighted' } else { 'Weighted' }`** edges

cor/cov method: `r params$degree.correlation` 

  * *only applies if network type is correlation/covariance*

```{r, include=FALSE, eval=FALSE}
rmarkdown::render('Analysis.Rmd', output_file = 'brca-center.html', params = list(normalization = 'center'), output_format = BiocStyle::html_document())
rmarkdown::render('Analysis.Rmd', output_file = 'brca-max.html', params = list(normalization = 'max'), output_format = BiocStyle::html_document())
```


```{r setup, include=FALSE}
# ComBat(matrix and category_id)
# plotMDS(matrix and some color stuff)
# inSilicoDB is good to understand that and validate results
knitr::opts_chunk$set(echo = TRUE, collapse = TRUE, tidy = TRUE)
```

```{r, message=FALSE, warning=FALSE, include=FALSE}
# Libraries
library(futile.logger)
library(parallel)
library(glmnet)
library(loose.rock)
library(digest)
library(ggplot2)
library(reshape2)
library(survival)
library(brca.data)
library(Vennerable)
library(limma)
library(tidyverse)
library(forcats)
library(survival.owl)
library(biclust)
#
library(glmSparseNet)

# In case classic glmnet is used
library(doMC)
registerDoMC(cores=params$n.cores)
#
devtools::load_all()
#
.Last.value <- base.dir(path = '/ssd_home/averissimo/work/rpackages/network.cox-cache')
.Last.value <- show.message(FALSE)
.Last.value <- flog.layout(layout.format('[~l] ~m'))
.Last.value <- flog.appender(appender.tee('logger.txt'))
theme_set(theme_minimal())
```

# Load and normalize data

**Data**

* *TCGA project*: **`r params$project`**
* *Tissue type*: **`r params$tissue`**
    * `r if(params$coding.genes) {'Only using coding genes'} else {'Using all genes (coding and non-coding)'}`
* *Degree calculation*: **`r params$degree.type`**

**Normalization**

* *LOG2 transform*: **`r if (params$log2) { 'yes' } else { 'no' }`**
* *Gene by gene*: **`r params$normalization`**

## Load TCGA data

```{r load.data}
my.data <- run.cache(prepare.tcga.survival.data.old, 
                     'brca', 
                     'primary.solid.tumor', 
                     #
                     #input.type                = 'rna',
                     normalization             = params$normalization,
                     log2.pre.normalize        = params$log2,
                     # include.negative.survival = FALSE,
                     handle.duplicates         = 'keep_first', 
                     coding.genes              = TRUE,
                     #
                     cache.prefix              = 'tcga-data',
                     show.message = TRUE)
#
clinical <- my.data$clinical
#
xdata     <- my.data$xdata
ydata     <- my.data$ydata
xdata.raw <- my.data$xdata.raw
#
#
xdata.digest.cache     <- my.data$xdata.digest
xdata.raw.digest.cache <- my.data$xdata.raw.digest
ydata.digest.cache     <- my.data$ydata.digest
#
rm(my.data)
```

## Load degree data

**Network processing**

* *Degree calculation*: `r params$degree.type`
* *Edge cutoff*: **`r params$degree.cutoff`**
* **`r if (params$degree.unweighted) { 'Unweighted' } else { 'Weighted' }`** edges

cor/cov method: `r params$degree.correlation` 

  * *only applies if network type is correlation/covariance*

```{r degree.load}
if (params$degree.type == 'oldie') {
  #
  # Load old matrix used in SPARSA conference
  load(sprintf('/home/averissimo/work/rpackages/brca.analysis/data/degree-%.6f.RData', params$degree.cutoff))
  
} else if (params$degree.type == 'correlation') {
  #
  # Load degree of network calculated summing the inverse of each weight
  degree <- degree.cor(xdata.raw, 
                       consider.unweighted = params$degree.unweighted, 
                       cutoff              = params$degree.cutoff, 
                       method              = params$degree.correlation,
                       n.cores = params$n.cores)
} else if (params$degree.type == 'covariance') {
  #
  # Load degree of network calculated using covariance
  degree <- degree.cov(xdata.raw, 
                       consider.unweighted = params$degree.unweighted, 
                       cutoff              = params$degree.cutoff, 
                       method              = params$degree.correlation,
                       n.cores = params$n.cores)
} else if (params$degree.type == 'sparsebn') {
  #
  # Load degree of network from sparsebn package (calulate bayesian network)
  degree <- degree.sparsebn(xdata.raw,
                            cutoff              = params$degree.cutoff, 
                            consider.unweighted = params$degree.unweighted,
                            n.cores = params$n.cores)
} else if (params$degree.type == 'string') {
  #
  # Load degree of STRING network downloaded from external sources
  degree <- run.cache(string.db.homo.sapiens) %>% {
    run.cache(build.string.network, ., use.names = 'ensembl')
    } %>% {
      .@x[.@x <= params$degree.cutoff] <- 0
      if (params$degree.unweighted) {
        .@x <- (.@x != 0) * 1
      }
      Matrix::colSums(.) + Matrix::rowSums(.)
    }
  
  #
  # Adds missing genes as nodes with 0 degree
  
  degree <- colnames(xdata.raw)[!colnames(xdata.raw) %in% names(degree)] %>% {
   c(degree, array(0, length(.), dimnames = list(.))) 
  } %>% { .[colnames(xdata.raw)] }
} else if (params$degree.type == 'string.pedro') {
  #
  # Load degree of STRING network downloaded from external sources
  load('/ssd_home/averissimo/work/rpackages/network.cox-big.files/saves/degree-string.RData')
  ix.names <- colnames(xdata) %in% names(degree_uw)
  degree <- degree_uw[colnames(xdata)]
}
```

## Test / Training sets

```{r test_train_sets}
set.seed(params$seed)
ixs        <- balanced.train.and.test(which(ydata$status), which(!ydata$status), train.perc = params$train)
xdata.test <- xdata[ixs$test,]
ydata.test <- ydata[ixs$test,]
#
xdata.train <- xdata[ixs$train,]
ydata.train <- ydata[ixs$train,]
```


```{r sets, echo=FALSE}
xdata.train.digest <- digest.cache(xdata.train)

flog.info('Size of sets: (size/events)\n * Train: %.2f%% :: %4d / %4d\n *  Test: %.2f%% :: %4d /%4d', 
          params$train * 100,
          nrow(xdata.train), 
          sum(ydata.train$status), 
          (1 - params$train) * 100,
          nrow(xdata.test),
          sum(ydata.test$status))
```

## Summary of data

### Data

```{r summary_data, echo=FALSE}
flog.info('Loaded data from %s TCGA', params$project)
flog.info('              type of tissue: %s', params$tissue)
flog.info('  observations (individuals): %d (%d event / %d censored)', nrow(xdata), sum(ydata$status), sum(!ydata$status))
flog.info('           variables (genes): %d', ncol(xdata))
flog.info('             non-zero degree: %d', sum(degree != 0))
```

### Survival

```{r surv_times, echo=FALSE}
ydata.year        <- ydata %>% 
  mutate(time = time / 365, status = factor(status)) %>%
  mutate(status = fct_recode(status,
                             'Alive (censored)' = 'FALSE',
                             'Dead' = 'TRUE'))
#
ggplot(ydata.year) + geom_freqpoly(aes(time, color = status), bins = 150) +
  theme_minimal() + xlab('Time (year)') + ggtitle('Distribution of time per event') +
  theme(legend.position = 'top')
```

```{r test.clinical.variables, fig.height=15, echo=FALSE, eval=FALSE}
# Test physiological Variables

# *note:* Plots with p-value `<= 0.05` are shown. Two types of p-values are used as criteria:

# 1. Univariate cox model
# 1. Log rank test when separating between high and low risk group

all.plots <- run.cache(test.all.clinical, clinical, ydata)

multiplot(plotlist = all.plots$plot.list, layout = all.plots$layout)
knitr::kable(dplyr::arrange(dplyr::select(all.plots$df, name, p.value, desc), p.value))
```

# Pre-processing

* Selects a random subset of genes (all if `r params$subset == Inf`)
* Prepares the degree vector to be used in `glmnet`

```{r sample.xdata, echo = FALSE}
# Sample xdata if it is necessary
xdata.ix <- seq(ncol(xdata))
xdata.ix.no.added <- xdata.ix

if (params$subset < ncol(xdata.train)) {
  set.seed(params$seed)
  xdata.ix <- sample(xdata.ix, params$subset)
} 
set.seed(params$seed)
xdata.train.digest <- digest.cache(xdata.train[, xdata.ix])
```

## Preparing degree vector

* Normalize degree between 0 and 1
* Hub: heuristic( 1 - degree )
* Orphan: heuristic( degree )
* `trans.fun` is a double power to scale the values

see `?glmSparseNet::heuristic.scale` or `?glmSparseNet::hub.heuristic`

```{r transformation_function}
# see ?glmSparseNet::heuristic.scale
trans.fun <- function(x) { heuristic.scale(x) + 0.2}
```

```{r prepare.penalty, echo=FALSE}
original.penalty.factor        <- degree[xdata.ix.no.added]
names(original.penalty.factor) <- colnames(xdata.train[,xdata.ix.no.added])

##########################
#                        #
#   SUPER IMPORTANT!!!!  #
#                        #
##########################
original.penalty.factor[is.na(original.penalty.factor)] <- 0
norm.orig.penalty.factor <- original.penalty.factor / max(original.penalty.factor[!is.na(original.penalty.factor)], 
                                                          na.rm = TRUE)
#
#
# DegreeCox (old and log(old))
#
penalty.factor.degree.log <- penalty.factor.degree.old <- 1 / norm.orig.penalty.factor

inf.ix <- is.infinite(penalty.factor.degree.old) # index for infinite values

# log(old)
log.penal                          <- log(penalty.factor.degree.old[!inf.ix]) + 1
penalty.factor.degree.log[!inf.ix] <- log.penal
penalty.factor.degree.log[inf.ix]  <- max(log.penal) + 1

# old
non.log                           <- penalty.factor.degree.old[!inf.ix]
penalty.factor.degree.old[inf.ix] <- max(non.log) + 1

#
# DegreeCox heuristic
#

tmp.degree_new                        <- norm.orig.penalty.factor
tmp.degree_new[is.na(tmp.degree_new)] <- 0
penalty.factor.degree.new             <-trans.fun(1 - tmp.degree_new)

#
# OrphanCox
#

tmp.orphan                    <- norm.orig.penalty.factor
tmp.orphan[is.na(tmp.orphan)] <- 1
penalty.factor.orphan         <- trans.fun(tmp.orphan)

my.df <- data.frame(ix                        = seq_along(penalty.factor.degree.old), 
                    penalty.factor.degree.old = penalty.factor.degree.old, 
                    penalty.factor.degree.new = penalty.factor.degree.new,
                    penalty.factor.degree.log = penalty.factor.degree.log,
                    penalty.factor.orphan     = penalty.factor.orphan,
                    original                  = original.penalty.factor)
```

### Original degree frequency

```{r plots_x_no_scale, echo=FALSE, fig.height=10, warning=FALSE}
transf.d <- melt.data.frame(my.df[,c('ix', 
                                     'original', 
                                     'penalty.factor.degree.old',
                                     'penalty.factor.degree.log',
                                     'penalty.factor.degree.new',
                                     'penalty.factor.orphan')], id.vars = c('ix'), variable_name = 'Type')

levels(transf.d$Type) <- levels(transf.d$Type) %>%
  gsub('original', 'Original', .) %>%
  gsub('penalty.factor.degree.old', 'Degree (old)', .) %>%
  gsub('penalty.factor.degree.log', 'Degree (log(old))', .) %>%
  gsub('penalty.factor.degree.new', 'Degree (heuristic)', .) %>%
  gsub('penalty.factor.orphan', 'Orphan', .)

if (!params$calc.params.old) {
  transf.d <- transf.d %>% 
    filter(Type != 'Degree (old)') %>%
    filter(Type != 'Degree (log(old))')
}

#degree.factor.freq.plot <- 
ggplot(transf.d) +
  geom_freqpoly(aes(value, color = Type), alpha = 0.8, bins = 200, size = 1.5) +
  theme_minimal() + theme(legend.position = 'none') +
  facet_wrap( ~ Type, ncol = 1, scale = 'free_x') +
  scale_y_continuous(trans = 'log10') +
  xlab('Penalty') +
  ylab('Frequency count (log10 scale)') + 
  ggtitle('Non scale on X')
```

```{r plots_x_scale, echo=FALSE, fig.height=10, warning=FALSE}
transf.d <- melt.data.frame(my.df[,c('ix', 
                                     'original', 
                                     'penalty.factor.degree.old',
                                     'penalty.factor.degree.log',
                                     'penalty.factor.degree.new',
                                     'penalty.factor.orphan')], id.vars = c('ix'), variable_name = 'Type')

levels(transf.d$Type) <- levels(transf.d$Type) %>%
  gsub('original', 'Original', .) %>%
  gsub('penalty.factor.degree.old', 'Degree (old)', .) %>%
  gsub('penalty.factor.degree.log', 'Degree (log(old))', .) %>%
  gsub('penalty.factor.degree.new', 'Degree (heuristic)', .) %>%
  gsub('penalty.factor.orphan', 'Orphan', .)

if (!params$calc.params.old) {
  transf.d <- transf.d %>% 
    filter(Type != 'Degree (old)') %>%
    filter(Type != 'Degree (log(old))')
}

ggplot(transf.d) +
  geom_freqpoly(aes(value, color = Type), alpha = 0.8, bins = 200, size = 1.5) +
  theme_minimal() + theme(legend.position = 'none') +
  facet_wrap( ~ Type, ncol = 1, scale = 'free_x') +
  scale_y_continuous(trans = 'log10') +
  scale_x_continuous(trans = 'log10') +
  xlab('Penalty (log10 scale)') +
  ylab('Frequency count (log10 scale)') + 
  ggtitle('Log scale on X')
```

# Model Inference

```{r list_init, include=FALSE}
models  <- lambdas <- coefs <- result <- table.data <- list()
```

```{r calc.models, echo=FALSE}
glmnet.params <- list()

for (target.name in names(params$target.vars)) {
  target <- params$target.vars[[target.name]]
  glmnet.params <- c(glmnet.params, list(list(penalty = rep(1, ncol(xdata.train)), name = 'glmnet', target = target, target.name = target.name)))
  glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.degree.new, name = 'degree_new', target = target, target.name = target.name)))
  glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.orphan, name = 'orphan', target = target, target.name = target.name)))
  if (params$calc.params.old) {
   glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.degree.old, name = 'degree_old', target = target, target.name = target.name)))
  glmnet.params <- c(glmnet.params, list(list(penalty = penalty.factor.degree.log, name = 'degree_log', target = target, target.name = target.name))) 
  }
}

outer.result <- mclapply(seq_along(glmnet.params), function(ix) {
#outer.result <- lapply(seq_along(glmnet.params), function(ix) {
  # flog.info('ix: %d', ix)
  el       <- glmnet.params[[ix]]
  ix.name  <- sprintf('%s.%s.%d', el$name, el$target.name, el$target)
  ix.cache <- sprintf('%s_models', el$name)
  # flog.info('ix: %s', ix.cache)
  # flog.info('ix: %s', ix.name)
  #
  suppressWarnings(
  result  <- glmSparseNet.cox(xdata        = xdata.train[,xdata.ix], 
                              ydata        = ydata.train, 
                              target.vars  = el$target, 
                              alpha        = params$alpha,
                              network      = el$penalty, 
                              xdata.digest = xdata.train.digest, 
                              force.recalc = FALSE)
  )
  
  #
  return(list(result = result, name = ix.name))
#})
}, mc.cores = min(params$n.cores, length(glmnet.params)), mc.allow.recursive = FALSE)


for (ix in outer.result) {
  result[[ix$name]]  <- ix$result
  models[[ix$name]]  <- ix$result$model
  lambdas[[ix$name]] <- ix$result$lambda
  coefs[[ix$name]]   <- ix$result$coef
}
```

```{r models_variables, echo=FALSE}
flog.info('Number of variables per model:')
for (ix in names(coefs)) {
  flog.info('  * %s:\t %d variables', ix, sum(coefs[[ix]] != 0))
}
flog.info('')
flog.info('note, selected variables could be slightly different from target, to have more accuracy increase nlambda in code')
```

# Results

## Relative risk distribution

Calculated using the inferred models and the train/test datasets. *The higher the better*.

```{r fitted.test.train.orphan, include=FALSE}
build.fit.df <- function(obj) {
  fitted.network <- data.frame()
  
  for (ix.name in names(obj)) {
    risk.a <- predict(obj[[ix.name]]$model, newx = xdata.train[,xdata.ix], s = obj[[ix.name]]$target, type = 'response')
    risk.b <- predict(obj[[ix.name]]$model, newx = xdata.test[,xdata.ix], s = obj[[ix.name]]$target, type = 'response')
    
    a <- data.frame(relative.risk = as.vector(risk.a), set = 'Train', type = ix.name, stringsAsFactors = FALSE)
    b <- data.frame(relative.risk = as.vector(risk.b), set = 'Test', type = ix.name, stringsAsFactors = FALSE)
    
    a$mean <- mean(a$relative.risk)
    b$mean <- mean(b$relative.risk)
    
    fitted.network <- rbind(fitted.network, a, b)
  }
  return(fitted.network)
}

this.list <- list()
for (ix.name in names(models)) {
  this.list[[ix.name]] <- list(model = models[[ix.name]], target = lambdas[[ix.name]])
}

fitted.network <- run.cache(build.fit.df, this.list, show.message = F)
```

```{r risk, fig.height=18, echo=FALSE}
ggplot(fitted.network) +
  geom_freqpoly(aes(relative.risk, color = set), bins = 150) + theme_minimal() +
  geom_vline(aes(xintercept = mean), linetype = 'dotted', color = '#999999') +
  geom_text(aes(x = mean, y = -.5, label = sprintf(' Mean of relative risk %g', mean), hjust = 0), color = '#999999', inherit.aes = FALSE, check_overlap = TRUE) + 
  facet_wrap( ~ type + set, ncol = 2) + 
  ggtitle('Distribution of risk in Classic model') +
  theme(legend.position = 'none')
```

## Kaplan-Meier Curves

```{r calc.km, include=FALSE}
#
km.train <- km.test <- list()
#
for (ix.name in names(coefs)) {
  this.coef <- list(ix.name = coefs[[ix.name]])
  km.train[[ix.name]] <- this.coef %>% glmSparseNetPaper::my.draw.kaplan(plot.title = 'Train set', xdata.train[, xdata.ix], ydata.train)
  km.test[[ix.name]]  <- this.coef %>% glmSparseNetPaper::my.draw.kaplan(plot.title = 'Test set',  xdata.test[, xdata.ix],  ydata.test)
}
```

```{r plot.km, echo=FALSE, fig.height=20}
my.km.train <- list()
my.km.test <- list()
ix <- 1
for (ix.name in names(coefs)) {
  my.km.train[[ix]] <- km.train[[ix.name]]$plot + km.name('Train', params$alpha, ix.name)
  my.km.test[[ix]]  <- km.test[[ix.name]]$plot  + km.name('Test',  params$alpha, ix.name)
  ix <- ix + 1
}

multiplot(plotlist = my.km.test, ncol = 1, layout = matrix(seq_along(my.km.test), byrow = T))
multiplot(plotlist = my.km.train, ncol = 1, layout = matrix(seq_along(my.km.train), byrow = T))
```

## C-Index

```{r c.index,echo=FALSE}
c.index.train <- list()
c.index.test  <- list()

#flog.info('C-index for train set:')

#
#
# Train
#

for (ix.name in names(coefs)) {
  c.index.train[[ix.name]] <- fit.risk(coefs[[ix.name]], xdata.train, ydata.train, ix.name,  show.message = TRUE)
}

#flog.info('')
#
#
# Test
#

#flog.info('C-index for test set:')

for (ix.name in names(coefs)) {
  c.index.test[[ix.name]] <- fit.risk(coefs[[ix.name]], xdata.test, ydata.test, ix.name,  show.message = TRUE)
}

```

Summary

```{r summary, echo=FALSE}
table.data <- data.frame()
for (ix.name in names(coefs)) {
  table.data <- rbind(table.data, data.frame(
                           weighted      = !params$degree.unweighted,
                           penalization  = params$degree.type,
                           project       = params$project,
                           tissue        = params$tissue,
                           cutoff        = params$degree.cutoff,
                           coding.genes  = params$coding.genes,
                           alpha         = params$alpha,
                           model         = ix.name,
                           nvars         = sum(coefs[[ix.name]] != 0),
                           km.train      = km.train[[ix.name]]$pvalue,
                           km.test       = km.test[[ix.name]]$pvalue,
                           c.index.train = c.index.train[[ix.name]],
                           c.index.test  = c.index.test[[ix.name]]))
}
knitr::kable(table.data)
```


## Non-zero genes

```{r non.zero.pre, include=FALSE}
coefs.v <- list()
non.zero.df.result <- NULL
for (ix.name in names(coefs)){
  flog.info('Working on %s', ix.name)
  coefs.v[[ix.name]] <- coefs[[ix.name]]
  non.zero.ix        <- which(coefs.v[[ix.name]] != 0)
  #
  names.tmp <- names(coefs.v[[ix.name]])[non.zero.ix]
  coef.tmp  <- coefs.v[[ix.name]][non.zero.ix]
  if (length(coefs.v) == 1) {
    flog.info('  * Len == 0')
    non.zero.df.result <- data.frame(gene.id = names.tmp, coef = coef.tmp)
    first.name <- ix.name
  } else {
    flog.info('  * Len > 0')
    non.zero.df2 <- data.frame(gene.id = names.tmp, coef = coef.tmp)
    suffix <- c('', sprintf('.%s', ix.name))
    non.zero.df.result  <- dplyr::full_join(non.zero.df.result, non.zero.df2, by = c('gene.id'), suffix = suffix)
  }
}
colnames(non.zero.df.result)[2] <- sprintf('coef.%s', first.name)
#
non.zero.df.out <- cbind(non.zero.df.result, degree = as.vector(original.penalty.factor[non.zero.df.result$gene.id]))
gene.ids <- non.zero.df.out$gene.id
```


```{r non.zero, include=FALSE}
gene.names <- gene.names(gene.ids)
new.t      <- non.zero.df.out
ixs        <- gene.names[unlist(sapply(new.t$gene.id, function(s) { which(gene.names$ensembl_gene_id == s) })),]
new.t$gene.id[new.t$gene.id %in% ixs$ensembl_gene_id] <- ixs$external_gene_name

gene.ids                  <- non.zero.df.out$gene.id
non.zero.df.out$gene.id   <- gsub('ENSG0*', 'ENSG', non.zero.df.out$gene.id)
non.zero.df.out$gene.name <- new.t$gene.id
col.ix <- colnames(non.zero.df.out) %in% c('gene.id', 'gene.name', 'degree')
non.zero.df.out <- non.zero.df.out[,c(which(col.ix), which(!col.ix))]
```

### Venn Diagram of selected genes

#### Overlap between models *(with same target number of variables)*

```{r venn.coef, echo=FALSE}
all.names  <- names(coefs)
all.names <- all.names[grep('^(degree_new)|^(orphan\\.)|^(glmnet\\.)', all.names)]
all.model  <- unique(gsub('^([a-zAZ]+)\\.(.+)$', '\\1', gsub('_new', '', all.names)))
all.origin <- gsub('^([a-zAZ]+)\\.(.+)$', '\\2', gsub('_new', '', all.names))

for (type in unique(all.origin)) {
  ll <- list()
  for (ix.name in all.names[which(grepl(type, all.names))]) {
     label <- gsub(sprintf('\\.%s', type), '', ix.name)
     label <- gsub('glmnet', 'classic', label)
     label <- proper(label)
     ll[[label]] <- sort(non.zero.df.out$gene.id[!is.na(non.zero.df.out[, sprintf('coef.%s', ix.name)])])
  }
  tryCatch({
    vv <- Venn(ll)
    gridExtra::grid.arrange(grid::grid.grabExpr(plot(vv, doWeights = FALSE)), top= sprintf('Target variables: %s', proper(type)))
  }, error = function(err) { flog.error('Probel with %s', err)})
}
```

### Table of genes in models

```{r genes.table, echo=FALSE}
knitr::kable(non.zero.df.out)
```

## Hallmarks of Cancer links

```{r hallmarks, fig.width=10, warning=FALSE, echo=FALSE}
my.hallmarks <- hallmarks(non.zero.df.out$gene.name)

df.no.hallmarks <- data.frame(gene.name = my.hallmarks$no.hallmakrs, stringsAsFactors = FALSE)

for (ix.name in names(coefs)) {
  df.no.hallmarks[, ix.name] <- (df.no.hallmarks$gene.name %in% non.zero.df.out[!is.na(non.zero.df.out[[paste0('coef.',ix.name)]]), 'gene.name']) * 1
}
melt(df.no.hallmarks, id.vars = 'gene.name') %>%
  filter(value > 0) %>%
  ggplot(aes(gene.name,variable, fill=value)) + geom_raster() + 
    theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position = 'none')
```

```{r biclust, fig.height=10, echo=FALSE}
df.scaled <- my.hallmarks$hallmarks
df.scaled <- data.frame(gene.name = rownames(df.scaled), df.scaled, stringsAsFactors = FALSE)

for (ix.name in names(coefs)) {
  df.scaled[, ix.name] <- (df.scaled$gene.name %in% non.zero.df.out[!is.na(non.zero.df.out[[paste0('coef.',ix.name)]]), 'gene.name']) * 1
}

for (ix.name in names(coefs)) {
  if (sum(df.scaled[[ix.name]] == 1) == 0) {
    flog.warn('No hallmark genes for: %s', ix.name)
    next
  }
  df.scaled.filter <- df.scaled[df.scaled[[ix.name]] == 1, !colnames(df.scaled) %in% names(coefs)]
  df.melt <- melt(df.scaled.filter, 
                  id.vars = c('gene.name')) %>% filter(value > 0)
  print(
    ggplot(df.melt, aes(gene.name,variable, fill=value)) + 
      geom_raster() +
      theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
      ggtitle(ix.name) +
      ggplot2::xlab('External Gene Name') + ggplot2::ylab('') +
        ggplot2::scale_fill_gradientn(colours = rev(grDevices::topo.colors(2)))
  )
  # my.mat <- df.scaled.filter[,-1]
  # tryCatch({
  # biclust(as.matrix(my.mat), method=BCBimax(), minr=2, minc=2, number=100) %>%
  #   drawHeatmap(x = as.matrix(my.mat), bicResult = ., number = 1) # shown in picture below
  # }, error = function(err) { flog.error('Error: %s', err)})
}
```

# `r params$ntimes` Runs

```{r calc_ntimes, echo=FALSE, eval=TRUE}
if (params$train >= 1) {
  flog.info("Train and test sets are the same, won't calculate %d times with random seeds", params$train)
  big.df <- data.frame()
} else if (params$ntimes == 1) {
  flog.info("Running only %d times, so won't calculate any more runs. Result above should suffice", params$ntimes)
  big.df <- data.frame()
} else {
  suppressWarnings(rm(xdata.train, xdata.test, ydata.train, ydata.test))
  set.seed(params$seed)
  seed.vec <- sample(1000 + (max(c(1:1e7,params$ntimes))))[1:params$ntimes]
  
  ntimes.results <- parallel::mclapply(seed.vec, function(seed) {
    return(run.cache(call.results,
                     seed, xdata, ydata, params$train, params$subset, 
                     penalty.factor.degree.new, 
                     penalty.factor.degree.old, 
                     penalty.factor.orphan,
                     params,
                     #
                     cache.digest = list(NULL, xdata.digest.cache, ydata.digest.cache),
                     cache.prefix = 'big-diff'))
  #}, mc.cores = 1, mc.allow.recursive = FALSE)
  }, mc.cores = min( params$n.cores), mc.allow.recursive = FALSE)
  
  #if (params$ntimes == 1) {
  #  ntimes.results <- list(ntimes.results)
  #}
  
  big.df <- data.frame()
  for (ix in seq_along(ntimes.results)) {
    el        <- ntimes.results[[ix]]$metrics
    for (ix.el in names(el)) {
      my.values <- sapply(names(el[[ix.el]]), function(ix.model) {el[[ix.el]][[ix.model]]})
      my.names  <- rep(ix.el, length(my.values))
      my.models <- names(el[[ix.el]])
      new.line  <- data.frame(metric = my.names, model = my.models, values = as.numeric(my.values), stringsAsFactors = FALSE)
      big.df    <- rbind(big.df, new.line)
    }
  }
  #big.df$model <- factor(big.df$model, levels = c('glmnet', 'degree', 'orphan'), labels = c('GLMNET', 'DegreeCox', 'OrphanCox'))
  big.df$metric <- factor(big.df$metric, levels = c('c.index.train', 'c.index.test', 'km.train', 'km.test'), 
                                                    labels = c('C-Index (Train set)', 'C-Index (Test set)', 'Log-rank (Train set)', 'Log-rank (Test set)'))
}
```

## C-Index distribution

```{r c.index.iter, echo=FALSE, fig.height=20}
if (nrow(big.df) > 0) {
  as.tbl(big.df) %>%
    filter(metric %in% c('C-Index (Train set)', 'C-Index (Test set)')) %>%
    filter(values >= 0) %>%
    ggplot() +
      geom_freqpoly(aes(values, color = model), alpha = .75, bins = 100) + 
      facet_wrap(model ~ metric, ncol = 2) +
      theme_minimal() + theme(legend.position = 'top')  
}
```

## Log-rank test on Kaplan-Meier models

Separated by high and low risk groups

```{r pvalue.itre, echo=FALSE, fig.height=15}
if (nrow(big.df) > 0) {
  
  big.df %>%
    #filter(model %in% c('glmnet.selected.25', 'glmnet.selected.25' , 'lmnet.selected.25')) %>%
    filter(metric %in% c('Log-rank (Test set)')) %>%
    ggplot() +
      geom_freqpoly(aes(values, color = model), alpha = .75, bins = 300) + 
      facet_wrap(model ~ metric, ncol = 1) +
      ggtitle('Distribution of Log-Rank up until 0.05') +
      theme_minimal() + theme(legend.position = 'top') + coord_cartesian(xlim = c(0, 0.1))
  
  big.df %>%
    #filter(model %in% c('glmnet.classic.cv.28', 'degree_new.classic.cv.28', 'orphan.classic.cv.28')) %>%
    filter(metric %in% c('Log-rank (Test set)')) %>%
    ggplot() +
      geom_freqpoly(aes(values, color = model), alpha = .75, bins = 30) + 
      facet_wrap(model ~ metric, ncol = 1) +
      ggtitle('Full distribution Log-rank') +
      theme_minimal() + theme(legend.position = 'top')
}
```

```{r}
if (nrow(big.df) > 0) {
  consensus <- list()
  all.conse <- list()
  
  for (ix in ntimes.results) {
   for (ix.2 in names(ix$coefs)) {
      all.conse[[ix.2]] <- c(all.conse[[ix.2]], (ix$coefs[[ix.2]] %>% { 
        names(.[. != 0]) 
      } ))
      consensus[[ix.2]] <- unique(c(consensus[[ix.2]], (ix$coefs[[ix.2]] %>% { 
        names(.[. != 0]) 
      } )))
    }
  }
  all.conse.tbl <- lapply(all.conse, table)
  # consensus.external <- lapply(consensus, gene.names)
}
```

```{r consensus.histogram, warning=FALSE, fig.height=10, echo=FALSE}
melt(all.conse) %>%
  mutate(L1.suffix = sub('[a-z0-9_]+\\.', '', L1)) %>%
  mutate(L1.prefix = sub('\\.[a-z0-9_]+\\.[a-z0-9_]+$', '', L1)) %>%
  #filter(value > 25) %>%
  ggplot() +
  geom_histogram(aes(value, color = L1.prefix, fill = L1.prefix), alpha = .4, stat = 'count') +
  theme(legend.position = 'top', axis.text.y = element_blank()) +
  xlab('Genes') + ylab('Number of times gene is selected') +
  facet_wrap( ~ L1.suffix, ncol = 1)
```

```{r consensus.count, echo=FALSE}
melt(all.conse.tbl) %>%
  mutate(L1.suffix = sub('[a-z0-9_]+\\.', '', L1)) %>%
  #filter(value > 25) %>%
  ggplot() +
  geom_point(aes(Var.1, value, color = L1), alpha = .4) +
  facet_wrap( ~ L1) +
  theme(legend.position = 'top', axis.text.y = element_blank()) +
  xlab('Genes') + ylab('Number of times gene is selected')
```


## Overlap between variables selected

```{r consensus.venn, echo=FALSE}
if (nrow(big.df) > 0) {
  all.names  <- names(coefs)
  all.names <- all.names[grep('^(degree_new)|^(orphan\\.)|^(glmnet\\.)', all.names)]
  all.model  <- unique(gsub('^([a-zAZ]+)\\.(.+)$', '\\1', gsub('_new', '', all.names)))
  all.origin <- gsub('^([a-zAZ]+)\\.(.+)$', '\\2', gsub('_new', '', all.names))
  
  for (type in unique(all.origin)) {
    ll <- list()
    for (ix.name in all.names[which(grepl(type, all.names))]) {
       label <- gsub(sprintf('\\.%s', type), '', ix.name)
       label <- gsub('glmnet', 'classic', label)
       label <- proper(label)
       ll[[label]] <- sort(consensus[[ix.name]])
    }
    tryCatch({
      vv <- Venn(ll)
      gridExtra::grid.arrange(grid::grid.grabExpr(plot(vv, doWeights = FALSE)), top= sprintf('Target variables: %s', proper(type)))
    }, error = function(err) { flog.error('Probel with %s', err)})
  }
}
```












# Parameters for the report

```{r parms, echo=FALSE}
max.chars <- max(sapply(names(params), nchar))
for (ix.names in sort(names(params))) {
  prefix <- paste(array(' ', max.chars - nchar(ix.names)), collapse = '')
  if (is.vector(params[[ix.names]]) && length(params[[ix.names]]) == 1) {
    if (is.list(params[[ix.names]])) {
      flog.info('  %s%s: %s', prefix, ix.names, paste(params[[ix.names]], collapse = ', '))
    }
    else if (is.character(params[[ix.names]])) {
      flog.info('  %s%s: %s', prefix, ix.names, params[[ix.names]])
    }  else if (is.infinite(params[[ix.names]])) {
      flog.info('  %s%s: %f', prefix, ix.names, params[[ix.names]])
    } else if (is.integer(params[[ix.names]])) {
      flog.info('  %s%s: % 11d', prefix, ix.names, params[[ix.names]])
    } else {
      flog.info('  %s%s: % 11.3f', prefix, ix.names, params[[ix.names]])
    }
  } else if (is.vector(params[[ix.names]])) {
    flog.info('  %s%s: %s', prefix, ix.names, paste(params[[ix.names]], collapse = ', '))
  } else {
    flog.info('  %s%s: (i do not know how to display this)', prefix, ix.names)
  }
}
```































```{r, eval=FALSE, include=FALSE}
rmarkdown::render('Analysis.Rmd', output_file = 'brca7.html', params = list(alpha = .7))
rmarkdown::render('Analysis.Rmd', output_file = 'brca3.html', params = list(alpha = .3))
rmarkdown::render('Analysis.Rmd', output_file = 'brca5.html', params = list(alpha = .5))
```


```{r, eval=FALSE, include=FALSE}
rmarkdown::render('Network_Penalization_TCGA.Rmd', output_file = 'brca.html', params = list(project = 'brca'))
rmarkdown::render('Network_Penalization_TCGA.Rmd', output_file = 'prad.html', params = list(project = 'prad'))
rmarkdown::render('Network_Penalization_TCGA.Rmd', output_file = 'skcm.html', params = list(project = 'skcm', tissue = 'metastatic'))
```


```{r, eval=FALSE, include=FALSE}
run.me <- function(my.params) {
  dir.create('reports', showWarnings = F)
  rmarkdown::render('Network_Penalization_TCGA.Rmd',
                    output_file = sprintf('./reports/project-%s__train-%.2f__alpha-%.2f__cutoff-%.4f__type-%s__unw-%s.html', 
                                          my.params$project,
                                          my.params$train,
                                          my.params$alpha,
                                          my.params$degree.cutoff,
                                          my.params$degree.type,
                                          my.params$degree.unweighted),
                    params = my.params)
}

my.list <-list(
  #
  # Covariance
  #
  # binary network
  #
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 1),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 1),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 1),
  list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.8),
  list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.8),
  list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.8),
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.9),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.9),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'brca', train = 0.9),
  #
  #
  # PROBLEM!!
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 1),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 1),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 1),
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.8),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.8),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.8),
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.9),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.9),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'prad', train = 0.9),
  #
  #
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 1),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 1),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 1),
  #list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.8),
  #list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.8),
  #list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.8),
  list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.9),
  list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.9),
  list(alpha = 0.7, degree.cutoff = 0, degree.type = 'string',  degree.unweighted = TRUE, project = 'skcm', train = 0.9),
  list(end = T)
  )

library(parallel)
library(foreach)
library(doParallel)

#cl<-makeCluster(3)
#registerDoParallel(cl)

#foreach(ix = my.list, .combine = c) %dopar% {
for (ix in my.list) {
 if (is.null(ix[['end']]) || !ix[['end']]) {
   run.me(ix)
 }
 NULL
}

#stopCluster(cl)
```


```{r, eval=FALSE, include=FALSE}
run.me <- function(my.params) {
  rmarkdown::render('Network_Penalization_TCGA.Rmd',
                    output_file = sprintf('alpha-%.2f__cutoff-%.4f__type-%s__unw-%s.html', 
                                          my.params$alpha,
                                          my.params$degree.cutoff,
                                          my.params$degree.type,
                                          my.params$degree.unweighted),
                    params = my.params)
}

(env.spa <- new.env()) %>% load('../saves/quantile.abs-sparsebn.RData', envir = .)
(env.cor <- new.env()) %>% load('../saves/quantile.abs-correlation.RData', envir = .)
(env.cov <- new.env()) %>% load('../saves/quantile.abs-covariance.RData', envir = .)

cor.spa <- env.spa$result
cor.cor <- env.cor$result
cor.cov <- env.cov$result

my.list <-list(
  #
  # Covariance
  #
  # binary network
  list(alpha = 1.0, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = TRUE),
  list(alpha = 0.5, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = TRUE),
  #
  # using weights
  list(alpha = 1.0, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = FALSE),
  list(alpha = 0.5, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = cor.cov['99.99%'], degree.type = 'covariance',  degree.unweighted = FALSE),
  #
  # Correlation
  #
  # binary network
  list(alpha = 0.5, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = TRUE),
  list(alpha = 1.0, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = TRUE),
  list(alpha = 0.5, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = TRUE),
  list(alpha = 1.0, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = TRUE),
  # using weights
  list(alpha = 0.5, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = FALSE),
  list(alpha = 1.0, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = cor.cor['99.99%'],  degree.type = 'correlation', degree.unweighted = FALSE),
  list(alpha = 0.5, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = FALSE),
  list(alpha = 1.0, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = cor.cor['99%'],     degree.type = 'correlation', degree.unweighted = FALSE),
  #
  # STRING (Pedro Martinho)
  # 
  # binary network
  list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string', degree.unweighted = TRUE),
  list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string', degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = 0, degree.type = 'string', degree.unweighted = TRUE),
  # using weights
  list(alpha = 0.5, degree.cutoff = 0, degree.type = 'string', degree.unweighted = FALSE),
  list(alpha = 1.0, degree.cutoff = 0, degree.type = 'string', degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = 0, degree.type = 'string', degree.unweighted = FALSE),
  #
  # SparseBN (João Brito)
  #
  # binary network
  list(alpha = 0.5, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = TRUE),
  list(alpha = 1.0, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = TRUE),
  list(alpha = 0.5, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = TRUE),
  list(alpha = 1.0, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = TRUE),
  list(alpha = 0.0, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = TRUE),
  # 
  list(alpha = 0.5, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = FALSE),
  list(alpha = 1.0, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = 0,              degree.type = 'sparsebn', degree.unweighted = FALSE),
  list(alpha = 0.5, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = FALSE),
  list(alpha = 1.0, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = FALSE),
  list(alpha = 0.0, degree.cutoff = cor.spa['99%'], degree.type = 'sparsebn', degree.unweighted = FALSE),
  #
  list(end = T)
  )

library(parallel)
library(foreach)
library(doParallel)

cl<-makeCluster(10)
registerDoParallel(cl)

foreach(ix = my.list, .combine = c) %dopar% {
 if (is.null(ix[['end']]) || !ix[['end']]) {
   run.me(ix)
 }
 NULL
}

stopCluster(cl)
```
